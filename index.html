<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Pengfei Zhang</title>
  
  <meta name="author" content="Pengfei Zhang">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" href="images/asusun.png" type="image/png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <i>Last update: 12/2025</i>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Pengfei Zhang</name>
              </p>
              <p>
                I am a final year Computer Science Ph.D. candidate at <a href="https://scai.engineering.asu.edu/">School of Computing and Augmented Intelligence</a> at <a href="https://www.asu.edu/">Arizona State University</a> advisored by Dr. Heewook Lee. My research interests lie at the fascinating crossroads of computational biology and large language models, with a particular emphasis on the field of cost-effective T cell immunotherapy.
              </p>
              <p>
                My work seeks to shed light on two key areas: first, developing computational strategies for accurate prediction of the binding affinity between T cell receptors (TCRs) and epitope sequences presented on abnormal cells; second, designing/generating TCR sequences tailored for personalized immunotherapy. This field holds the potential to substantially expedite and reduce the cost of wet-lab experiments, paving the way for solutions to a wide array of diseases. <span style="color:red;">Actively seeking Research Scientist or Postdoctoral positions in machine learning and computational biology starting in early 2026.</span>
              </p>
              <p style="text-align:center">
                <a href="mailto:pzhang84@asu.edu">Email</a> &nbsp/&nbsp
                <a href="data/Pengfei_Zhang_CS_PhD_Arizona_State_University_Resume.pdf">CV</a> &nbsp/&nbsp
                <!-- <a href="data/pengfei-bio.txt">Bio</a> &nbsp/&nbsp -->
                <a href="https://scholar.google.com/citations?user=i0l0OzYAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/pengfei-zhang-4115b6191/">LinkedIn</a> &nbsp/&nbsp
                <!-- <a href="https://twitter.com/Pengfei17365177">Twitter</a> &nbsp/&nbsp -->
                <!-- <a href="readlist.html">Reading List</a> &nbsp -->
                <!-- <a href="https://github.com/jonbarron/">Github</a> -->
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/pengfei_circle1.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/pengfei_circle1.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                <!-- I'm interested in computer vision, machine learning, optimization, and image processing. Much of my research is about inferring the physical world (shape, motion, color, light, etc) from images.  -->
                I study how to improve <strong>conditional sequence generation</strong> using self-contemplating <strong>prompts design</strong>, <strong>hallucination-driven reward model refinement</strong>, and modular strategies that <strong>mitigate reward hacking</strong>. I also explore <strong>representation learning</strong> and <strong>active learning</strong> to enhance model efficiency and robustness.
                Representative papers are <span class="highlight">highlighted</span>.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
				
    
    <tr bgcolor="#ffffd0">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <img src="images/tcr-reward-design.png" width="160">
        </div>
      </td>

      <td style="padding:20px;width:75%;vertical-align:middle">
        <papertitle>Mitigating Goodhart’s Law in Epitope-Conditioned TCR Generation Using Plug-and-Play Reward Designs</papertitle>
        <br>
        <strong>Pengfei Zhang</strong>, Fredo Guan, Xiaoyi He, Hao Mei, Gloria Grama, Seojin Bang, Heewook Lee
        <br>
        <span style="color:red;"><em>RECOMB</em> (Research in Computational Molecular Biology), Under Review 2026</span>
        <br>
        <a href="#" onclick="return false;">paper (coming soon)</a> /
        <a href="https://github.com/Lee-CBG/TCRRobustRewardDesign" target="_blank" rel="noopener noreferrer">github</a>
        <p></p>
        <p>
          A modular reward-design framework that mitigates reward hacking and Goodhart-style failures in reinforcement learning. 
          We combine reward smoothing, ensemble predictors, max-margin objectives, and contrastive alignment to stabilize training and 
          preserve authenticity in sequence generation. Demonstrated through large-scale generative modeling experiments on biological sequence data.
        </p>
      </td>
    </tr>



    <tr bgcolor="#ffffd0">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <img src='images/bap-attack.png' width="160">
        </div>
        
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
          <papertitle>Iterative Attack-and-Defend Framework for Improving TCR-Epitope Binding Prediction Models</papertitle>
        <br>
          <strong>Pengfei Zhang</strong>, Hao Mei, Seojin Bang, Heewook Lee
        <br>
        <span style="color:red;"><em>ISMB/ECCB (Intelligent Systems for Molecular Biology); Bioinformatics Proceedings</em>, 2025</span>
        <br>
        <a href="https://doi.org/10.1093/bioinformatics/btaf224" target="_blank" rel="noopener noreferrer">paper</a> /
        <a href="https://github.com/Lee-CBG/BAP_Attack_n_Defend">github</a> /
        <a href="https://github.com/Lee-CBG/BAP_Attack_n_Defend/blob/main/figures/Zhang_Pengfei_42x42.pdf">poster</a>
        <p></p>
        <p>A negative data augmentation technique built on a fine-tuned protein language model and RLAIF. We reframe LLM-style hallucination as a powerful baseline for exposing the limitations and vulnerabilities of reward models. It improves model robustness through iterative attack-and-defense—demonstrated in the context of biological sequences.</p>
      </td>
    </tr>      
    
    <tr bgcolor="#ffffd0">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <img src='images/tcrgen.png' width="160">
        </div>
        
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
          <papertitle>Self-Contemplating In-Context Learning Enhances T Cell Receptor Generation for Novel Epitopes</papertitle>
        <br>
          <strong>Pengfei Zhang</strong>, Sonal Sujit Prabhu, Seojin Bang, Heewook Lee
        <br>
        <span style="color:red;"><em>Accepted in MLCB (Machine Learning in Computational Biology); PMLR Proceedings</em>, 2025</span>
        <br>
        <a href="https://www.biorxiv.org/content/10.1101/2025.01.27.634873v1">paper</a> /
        <a href="https://github.com/Lee-CBG/TCRGen">github</a> 
        <p></p>
        <p>An in-context learning framework for therapeutic sequence design using large language models (LLMs). We introduce a self-reflective prompting strategy, where the model generates and refines its own prompts to iteratively improve output—without any gradient updates or fine-tuning. This enables plug-and-play generalization to novel targets, with applications in drug discovery and protein design.</p>
      </td>
    </tr>


    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <img src='images/activetcr.png' width="160">
        </div>
        
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
          <papertitle>Active Learning Framework for Cost-Effective TCR-Epitope Binding Affinity Prediction</papertitle>
        <br>
          <strong>Pengfei Zhang</strong>, Seojin Bang, Heewook Lee
        <br>
        <em>IEEE BIBM (International Conference on Bioinformatics and Biomedicine)</em>, 2023
        <br>
        <a href="https://ieeexplore.ieee.org/document/10385683">paper</a> /
        <a href="https://github.com/Lee-CBG/ActiveTCR">github</a> 
        <p></p>
        <p>A unified data optimization framework (dubbed ActiveTCR) that integrates active learning and TCR-epitope binding affinity prediction models. In two distinct use cases, ActiveTCR demonstrated superior performance over passive learning, notably cutting annotation costs approximately half and minimizing redundancy by over 40% - all without compromising on model performance. ActiveTCR stands as the first systematic exploration into the realm of data optimization for TCR-epitope binding affinity prediction.</p>
      </td>
    </tr>      
		
    <tr bgcolor="#ffffd0">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <img src='images/catelmo.png' width="160">
        </div>
       
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
          <papertitle>Context-Aware Amino Acid Embedding Advances Analysis of TCR-Epitope Interactions</papertitle>
        <br>
         <strong>Pengfei Zhang</strong>, Seojin Bang, Michael Cai, Heewook Lee
        <br>
        <span style="color:red;"><em>eLife</em>, 2023</span>
        <br>
				<a href="https://elifesciences.org/reviewed-preprints/88837">paper</a> /
        <a href="https://github.com/Lee-CBG/catELMo">github</a> / 
        <a href="https://github.com/Lee-CBG/catELMo/blob/main/figures/Zhang_Pengfei_42x42.pdf">poster</a> 
        <p></p>
        <p>Introducing catELMo, a effective and efficient amino acid embedding model, specifically tailored for T cell receptors. This advanced model facilitates an impressive boost of over 20% in absolute AUC when predicting binding affinity for unseen or novel epitopes, outperforming the conventional BLOSUM62. Moreover, catELMo exhibits an extraordinary capacity to maintain comparable performance to BLOSUM62, while reducing about 93% training data, making it a game-changer in the field of TCR analysis.</p>
      </td>
    </tr>


    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <img src='images/pite.png' width="160">
        </div>
        
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
          <papertitle>PiTE: TCR-epitope Binding Affinity Prediction Pipeline using Transformer-based Sequence Encoder</papertitle>
        <br>
          <strong>Pengfei Zhang</strong>, Seojin Bang, Heewook Lee
        <br>
        <em>PSB (Pacific Symposium on Biocomputing)</em>, 2022
        <br>
        <a href="https://www.worldscientific.com/doi/pdf/10.1142/9789811270611_0032">paper</a> /
        <a href="https://github.com/Lee-CBG/PiTE">github</a> /
        <a href="https://github.com/Lee-CBG/PiTE/blob/main/Supplementary/PiTE_PSB23_Poster.pdf">poster</a> 
        <p></p>
        <p>How to better summarize multiple amino-acid-level embeddings into a single sequence-level embedding compared to average pooling? We build sequence encoders utilizing various structures including Transformer, BiLSTM, and ByteNet, and propose PiTE, a state-of-the-art two-step pipeline designed for TCR-epitope binding affinity prediction. </p>
      </td>
    </tr> 


    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <img src='images/atm-tcr.png' width="160">
        </div>
        
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
          <papertitle>ATM-TCR: TCR-Epitope Binding Affinity Prediction using a Multi-Head Self-Attention Model</papertitle>
        <br>
          Michael Cai, Seojin Bang, <strong>Pengfei Zhang</strong>, Heewook Lee
        <br>
        <em>Front Immunol</em>, 2022
        <br>
        <a href="https://www.frontiersin.org/articles/10.3389/fimmu.2022.893247/full">paper</a> /
        <a href="https://github.com/Lee-CBG/ATM-TCR">github</a> 
        <p></p>
        <p>ATM-TCR leverages multi-head self-attention mechanisms to capture biological contextual information and improves generalization ff TCR-epitope binding affinity prediction models. A novel application of the attention map to improve out-of-sample performance by demonstrating on recent SARS-CoV-2 data.</p>
      </td>
    </tr> 
		  




        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Services</heading>
              <ul>
                

                <li>
                  <b>Reviewer&nbsp;</b>
                  <ul>
                    <li>MLCB, 2025</li>
                    <li>GenBio@NeurIPS, 2023, 2025</li>
                    <li>PSB, 2023</li>
                    <li>ASU GPSA Travel Grant, 2020, 2021</li>
                    <li>ASU GPSA Research Grant, 2020, 2021</li>
                  </ul>
                </li>

                <li>
                  <b>Sub-reviewer&nbsp;</b>
                  <ul>
                    <li>RECOMB, 2023</li>
                    <li>ISMB, 2022, 2025</li>
                    <li>ACM-BCB, 2022</li>
                  </ul>
                </li>

              </ul> 
                           
            </td>
          </tr>


          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <heading>Awards</heading>
                <ul>
                    <li>ACM-ASU: Reserach Symposium & Competition, 2nd place, 2025</li>
                    <li>ASU Outstanding Research Award, 2024</li>
                    <li>Pacific Symposium on Biocomputing (PSB 2023) Travel Award, 2023</li>
                    <li>ASU GPSA Travel Grant Individual Award, 2022</li>
                    <li>ASU Biodesign Travel Award, 2022</li>
                    <li>ASU SCAI Travel Award, 2022</li>
                </ul> 
                             
              </td>
            </tr>


        <!-- </tbody></table>

        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
					
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/cvf.jpg"></td>
            <td width="75%" valign="center">
              <a href="https://cvpr2022.thecvf.com/area-chairs">Area Chair, CVPR 2022</a>
              <br>
              <a href="http://cvpr2021.thecvf.com/area-chairs">Area Chair & Longuet-Higgins Award Committee Member, CVPR 2021</a>
              <br>
              <a href="http://cvpr2019.thecvf.com/area_chairs">Area Chair, CVPR 2019</a>
              <br>
              <a href="http://cvpr2018.thecvf.com/organizers/area_chairs">Area Chair, CVPR 2018</a>
            </td>
          </tr> -->

					
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Source code from <a href="https://jonbarron.info/">Jon's website</a>.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
